{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Michał Gromadzki"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 17:10:48.727923: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-26 17:10:51.716141: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "SEED = 1337\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alert_ids</th>\n",
       "      <th>client_code</th>\n",
       "      <th>categoryname</th>\n",
       "      <th>ip</th>\n",
       "      <th>ipcategory_name</th>\n",
       "      <th>ipcategory_scope</th>\n",
       "      <th>parent_category</th>\n",
       "      <th>grandparent_category</th>\n",
       "      <th>overallseverity</th>\n",
       "      <th>timestamp_dist</th>\n",
       "      <th>...</th>\n",
       "      <th>thrcnt_week</th>\n",
       "      <th>thrcnt_day</th>\n",
       "      <th>p6</th>\n",
       "      <th>p9</th>\n",
       "      <th>p5m</th>\n",
       "      <th>p5w</th>\n",
       "      <th>p5d</th>\n",
       "      <th>p8m</th>\n",
       "      <th>p8w</th>\n",
       "      <th>p8d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Slg</td>\n",
       "      <td>RLJ</td>\n",
       "      <td>Exploit</td>\n",
       "      <td>MW.YB.50.64</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>Internet</td>\n",
       "      <td>7</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>298</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WKM</td>\n",
       "      <td>UZT</td>\n",
       "      <td>Exploit</td>\n",
       "      <td>IJ.NW.77.74</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>Internet</td>\n",
       "      <td>7</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dkm</td>\n",
       "      <td>ZZW</td>\n",
       "      <td>Attack</td>\n",
       "      <td>YT.LB.36.21</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>Internet</td>\n",
       "      <td>7</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3601</td>\n",
       "      <td>602</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RIX</td>\n",
       "      <td>QXG</td>\n",
       "      <td>Attack</td>\n",
       "      <td>172.BW.LB.105</td>\n",
       "      <td>PRIV-172</td>\n",
       "      <td>Private network</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qFU</td>\n",
       "      <td>PDU</td>\n",
       "      <td>Exploit</td>\n",
       "      <td>YT.LB.32.110</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>Internet</td>\n",
       "      <td>7</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>258273</td>\n",
       "      <td>...</td>\n",
       "      <td>131</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  alert_ids client_code categoryname             ip ipcategory_name   \n",
       "0       Slg         RLJ      Exploit    MW.YB.50.64        INTERNET  \\\n",
       "1       WKM         UZT      Exploit    IJ.NW.77.74        INTERNET   \n",
       "2       dkm         ZZW       Attack    YT.LB.36.21        INTERNET   \n",
       "3       RIX         QXG       Attack  172.BW.LB.105        PRIV-172   \n",
       "4       qFU         PDU      Exploit   YT.LB.32.110        INTERNET   \n",
       "\n",
       "  ipcategory_scope  parent_category grandparent_category  overallseverity   \n",
       "0         Internet                7                    A                3  \\\n",
       "1         Internet                7                    A                5   \n",
       "2         Internet                7                    A                3   \n",
       "3  Private network                1                    A                3   \n",
       "4         Internet                7                    A                3   \n",
       "\n",
       "   timestamp_dist  ...  thrcnt_week  thrcnt_day  p6 p9  p5m  p5w  p5d  p8m   \n",
       "0               0  ...          298          42   1  0    1    1    1    1  \\\n",
       "1               0  ...           11           3   1  0    1    1    1    1   \n",
       "2               0  ...         3601         602   1  0    3    1    1    1   \n",
       "3               0  ...           12           4   1  0    3    1    1    2   \n",
       "4          258273  ...          131          20   1  0    1    1    1    1   \n",
       "\n",
       "   p8w  p8d  \n",
       "0    1    1  \n",
       "1    1    1  \n",
       "2    1    1  \n",
       "3    1    1  \n",
       "4    1    1  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"data/cybersecurity_test.csv\",sep=\"|\").drop([\"n1\",\"n2\",\"n3\",\"n4\",\"n5\",\"n6\",\"n7\",\"n8\",\"n9\",\"n10\",\"score\"],axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alert_ids</th>\n",
       "      <th>client_code</th>\n",
       "      <th>notified</th>\n",
       "      <th>categoryname</th>\n",
       "      <th>ip</th>\n",
       "      <th>ipcategory_name</th>\n",
       "      <th>ipcategory_scope</th>\n",
       "      <th>parent_category</th>\n",
       "      <th>grandparent_category</th>\n",
       "      <th>overallseverity</th>\n",
       "      <th>...</th>\n",
       "      <th>thrcnt_week</th>\n",
       "      <th>thrcnt_day</th>\n",
       "      <th>p6</th>\n",
       "      <th>p9</th>\n",
       "      <th>p5m</th>\n",
       "      <th>p5w</th>\n",
       "      <th>p5d</th>\n",
       "      <th>p8m</th>\n",
       "      <th>p8w</th>\n",
       "      <th>p8d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nhq</td>\n",
       "      <td>DPM</td>\n",
       "      <td>0</td>\n",
       "      <td>Attack</td>\n",
       "      <td>YT.LB.32.21</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>Internet</td>\n",
       "      <td>7</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4160</td>\n",
       "      <td>675</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XZt</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0</td>\n",
       "      <td>Exploit</td>\n",
       "      <td>192.SL.UK.94</td>\n",
       "      <td>PRIV-192</td>\n",
       "      <td>Private network</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bBz</td>\n",
       "      <td>CHP</td>\n",
       "      <td>0</td>\n",
       "      <td>Attack</td>\n",
       "      <td>YT.LB.38.21</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>Internet</td>\n",
       "      <td>7</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3788</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZNr</td>\n",
       "      <td>HPS</td>\n",
       "      <td>0</td>\n",
       "      <td>Attack</td>\n",
       "      <td>JX.NY.13.20</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>Internet</td>\n",
       "      <td>7</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>565</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poV</td>\n",
       "      <td>OSC</td>\n",
       "      <td>0</td>\n",
       "      <td>Attack</td>\n",
       "      <td>YT.LB.32.21</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>Internet</td>\n",
       "      <td>7</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2790</td>\n",
       "      <td>632</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  alert_ids client_code  notified categoryname            ip ipcategory_name   \n",
       "0       Nhq         DPM         0       Attack   YT.LB.32.21        INTERNET  \\\n",
       "1       XZt         FIN         0      Exploit  192.SL.UK.94        PRIV-192   \n",
       "2       bBz         CHP         0       Attack   YT.LB.38.21        INTERNET   \n",
       "3       ZNr         HPS         0       Attack   JX.NY.13.20        INTERNET   \n",
       "4       poV         OSC         0       Attack   YT.LB.32.21        INTERNET   \n",
       "\n",
       "  ipcategory_scope  parent_category grandparent_category  overallseverity   \n",
       "0         Internet                7                    A                3  \\\n",
       "1  Private network                1                    A                5   \n",
       "2         Internet                7                    A                4   \n",
       "3         Internet                7                    A                4   \n",
       "4         Internet                7                    A                4   \n",
       "\n",
       "   ...  thrcnt_week  thrcnt_day  p6  p9 p5m  p5w  p5d  p8m  p8w  p8d  \n",
       "0  ...         4160         675   1   0   2    1    1    1    1    1  \n",
       "1  ...            9           2   4  12   3    2    2    2    1    1  \n",
       "2  ...         3788         628   1   0   2    2    1    2    2    1  \n",
       "3  ...          565          96   0   0   2    2    2    2    2    2  \n",
       "4  ...         2790         632   1   0   1    1    1    1    1    1  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/cybersecurity_training.csv\",sep=\"|\").drop([\"n1\",\"n2\",\"n3\",\"n4\",\"n5\",\"n6\",\"n7\",\"n8\",\"n9\",\"n10\",\"score\"],axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_train = np.load(\"data/result_train.npy\",allow_pickle=True)\n",
    "res_test = np.load(\"data/result_test.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_train_df = pd.DataFrame(res_train,columns=[\"alert_ids\",\"val1\", \"val2\", \"val3\", \"val4\"])\n",
    "res_test_df = pd.DataFrame(res_test,columns=[\"alert_ids\",\"val1\", \"val2\", \"val3\", \"val4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate embeddigns\n",
    "res_test_df = res_test_df.groupby(\"alert_ids\").mean().astype(\"float32\")\n",
    "res_train_df = res_train_df.groupby(\"alert_ids\").mean().astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test_df.reset_index(inplace=True)\n",
    "res_train_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add embedding to base data\n",
    "df_test = df_test.merge(res_test_df, on=\"alert_ids\")\n",
    "df_train = df_train.merge(res_train_df, on=\"alert_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = df_train[\"notified\"].values\n",
    "df_train = df_train.drop([\"alert_ids\",\"notified\"],axis=1)\n",
    "df_test = df_test.drop([\"alert_ids\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['client_code',\n",
       " 'categoryname',\n",
       " 'ip',\n",
       " 'ipcategory_name',\n",
       " 'ipcategory_scope',\n",
       " 'grandparent_category',\n",
       " 'weekday',\n",
       " 'dstipcategory_dominate',\n",
       " 'srcipcategory_dominate']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select column to tokenize\n",
    "columns = df_train.columns\n",
    "numerical_columns = df_train.describe().columns\n",
    "transform_columns = [col for col in columns if col not in numerical_columns]\n",
    "transform_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ip(text):\n",
    "    text = tf.strings.split(text,sep=\".\")\n",
    "    return text.to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 17:12:23.479619: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-26 17:12:23.799496: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-26 17:12:23.799618: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-26 17:12:23.806682: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-26 17:12:23.806816: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-26 17:12:23.806863: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-26 17:12:30.306083: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-26 17:12:30.306370: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-26 17:12:30.306395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-06-26 17:12:30.306493: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-26 17:12:30.306826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3265 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "vectorizers = []\n",
    "results_train = []\n",
    "results_test = []\n",
    "for col in transform_columns:\n",
    "    std = preprocess_ip if col == \"ip\" else None\n",
    "    vectorizer = tf.keras.layers.TextVectorization(standardize=std, split=None, name=f\"{col}\")\n",
    "    vectorizer.adapt(df_train[f\"{col}\"].values)\n",
    "    results_train.append(vectorizer(df_train[f\"{col}\"].values).numpy())\n",
    "    results_test.append(vectorizer(df_test[f\"{col}\"].values).numpy())\n",
    "    vectorizers.append(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more columns to tokenize\n",
    "transformcols2 = [\"parent_category\", \"overallseverity\", \"start_hour\", \"start_minute\", \"start_second\",\n",
    "                    \"isiptrusted\", \"untrustscore\", \"flowscore\", \"trustscore\", \"enforcementscore\",\n",
    "                    \"dstportcategory_dominate\", \"srcportcategory_dominate\", \"p6\", \"p5m\", \"p5w\", \"p5d\", \"p8m\", \"p8w\", \"p8d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in transformcols2:\n",
    "    vectorizer = tf.keras.layers.TextVectorization(standardize=None, split=None, name=f\"{col}\")\n",
    "    x1, x2 = [str(item) for item in df_train[f\"{col}\"]], [str(item) for item in df_test[f\"{col}\"]]\n",
    "    vectorizer.adapt(x1)\n",
    "    results_train.append(vectorizer(x1).numpy())\n",
    "    results_test.append(vectorizer(x2).numpy())\n",
    "    vectorizers.append(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rest of the columns - continous features\n",
    "transform_columns.extend(transformcols2)\n",
    "x_train = df_train[df_train.columns[~df_train.columns.isin(transform_columns)]].to_numpy().copy()\n",
    "x_test = df_test[df_test.columns[~df_test.columns.isin(transform_columns)]].to_numpy().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = [np.reshape(np.array(item), (len(item), -1)) for item in results_train]\n",
    "results_test = [np.reshape(np.array(item), (len(item), -1)) for item in results_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 26)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39427, 26)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='models/model_checkpoint',\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class emb_layer(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, n_embed, vectorizer):\n",
    "        super(emb_layer, self).__init__()\n",
    "        self.vectorizer = vectorizer\n",
    "        self.n_embed = n_embed * 2 if self.vectorizer.name == \"ip\" else n_embed\n",
    "        self.embedding = tf.keras.layers.Embedding(self.vectorizer.vocabulary_size(), self.n_embed, input_length=1)\n",
    "        self.lstm1 = tf.keras.layers.LSTM(units, return_sequences=True)\n",
    "        self.lstm2 = tf.keras.layers.LSTM(units)\n",
    "        self.flat = tf.keras.layers.Flatten()\n",
    "        self.mlp1 = tf.keras.layers.Dense(units, activation=\"relu\")\n",
    "        self.mlp2 = tf.keras.layers.Dense(units, activation=\"relu\")\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        if self.vectorizer.name == \"ip\":\n",
    "            x = self.lstm1(x)\n",
    "            x = self.lstm2(x)\n",
    "        else:\n",
    "            x = self.flat(x)\n",
    "        x = self.mlp1(x)\n",
    "        x = self.mlp2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, units, n_embed, vectorizers):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.emebd_layers = [emb_layer(units, n_embed, vec) for vec in vectorizers]\n",
    "        self.conc = tf.keras.layers.Concatenate()\n",
    "        self.mlp1 = tf.keras.layers.Dense(32, activation=\"relu\")\n",
    "        self.mlp2 = tf.keras.layers.Dense(64, activation=\"relu\")\n",
    "        self.main_mlp1 = tf.keras.layers.Dense(len(vectorizers)*units+64, activation=\"relu\")\n",
    "        self.main_mlp2 = tf.keras.layers.Dense(64, activation=\"relu\")\n",
    "        self.dropout = tf.keras.layers.Dropout(0)\n",
    "        self.classifier = tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        main_inputs, emb_inputs = inputs\n",
    "\n",
    "        xs = [embed_layer(emb_inputs[i]) for i,embed_layer in enumerate(self.emebd_layers)]\n",
    "        x1 = self.mlp1(main_inputs)\n",
    "        x1 = self.mlp2(x1)\n",
    "\n",
    "        x = self.conc([x1,*xs])\n",
    "        x = self.main_mlp1(x)\n",
    "        x = self.main_mlp2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(32,8, vectorizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=tf.keras.losses.BinaryCrossentropy(), metrics=[\"accuracy\", tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 17:16:53.630546: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-26 17:16:53.635241: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-26 17:16:53.638684: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-26 17:16:54.250362: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-26 17:16:54.254100: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-26 17:16:54.256845: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-26 17:17:11.062915: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-26 17:17:11.067001: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-26 17:17:11.071462: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-26 17:17:11.580799: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-26 17:17:11.587387: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-26 17:17:11.590996: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-26 17:17:38.764008: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8901\n",
      "2023-06-26 17:17:41.035474: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fb7c801a6e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-26 17:17:41.035614: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 2060 with Max-Q Design, Compute Capability 7.5\n",
      "2023-06-26 17:17:41.112208: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-06-26 17:17:42.472649: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247/247 [==============================] - ETA: 0s - loss: 61.7108 - accuracy: 0.9070 - auc: 0.5748"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 17:19:20.212046: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-26 17:19:20.216672: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-26 17:19:20.219652: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-26 17:19:20.537545: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-26 17:19:20.541175: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-26 17:19:20.543977: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.21324, saving model to models/model_checkpoint\n",
      "247/247 [==============================] - 153s 287ms/step - loss: 61.7108 - accuracy: 0.9070 - auc: 0.5748 - val_loss: 1.2132 - val_accuracy: 0.8670 - val_auc: 0.7662\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.7802 - accuracy: 0.9352 - auc: 0.7389\n",
      "Epoch 2: val_loss improved from 1.21324 to 0.34604, saving model to models/model_checkpoint\n",
      "247/247 [==============================] - 34s 138ms/step - loss: 0.7802 - accuracy: 0.9352 - auc: 0.7389 - val_loss: 0.3460 - val_accuracy: 0.9348 - val_auc: 0.7921\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.2194 - accuracy: 0.9423 - auc: 0.8216\n",
      "Epoch 3: val_loss improved from 0.34604 to 0.17423, saving model to models/model_checkpoint\n",
      "247/247 [==============================] - 30s 121ms/step - loss: 0.2194 - accuracy: 0.9423 - auc: 0.8216 - val_loss: 0.1742 - val_accuracy: 0.9412 - val_auc: 0.8714\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.1718 - accuracy: 0.9429 - auc: 0.8676\n",
      "Epoch 4: val_loss did not improve from 0.17423\n",
      "247/247 [==============================] - 33s 132ms/step - loss: 0.1718 - accuracy: 0.9429 - auc: 0.8676 - val_loss: 0.1782 - val_accuracy: 0.9404 - val_auc: 0.8660\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.1576 - accuracy: 0.9427 - auc: 0.8883\n",
      "Epoch 5: val_loss improved from 0.17423 to 0.17048, saving model to models/model_checkpoint\n",
      "247/247 [==============================] - 30s 121ms/step - loss: 0.1576 - accuracy: 0.9427 - auc: 0.8883 - val_loss: 0.1705 - val_accuracy: 0.9405 - val_auc: 0.8717\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.1478 - accuracy: 0.9427 - auc: 0.9032\n",
      "Epoch 6: val_loss improved from 0.17048 to 0.16911, saving model to models/model_checkpoint\n",
      "247/247 [==============================] - 28s 115ms/step - loss: 0.1478 - accuracy: 0.9427 - auc: 0.9032 - val_loss: 0.1691 - val_accuracy: 0.9403 - val_auc: 0.8728\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.1467 - accuracy: 0.9427 - auc: 0.9055\n",
      "Epoch 7: val_loss improved from 0.16911 to 0.16714, saving model to models/model_checkpoint\n",
      "247/247 [==============================] - 51s 206ms/step - loss: 0.1467 - accuracy: 0.9427 - auc: 0.9055 - val_loss: 0.1671 - val_accuracy: 0.9407 - val_auc: 0.8812\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.1426 - accuracy: 0.9430 - auc: 0.9120\n",
      "Epoch 8: val_loss did not improve from 0.16714\n",
      "247/247 [==============================] - 30s 120ms/step - loss: 0.1426 - accuracy: 0.9430 - auc: 0.9120 - val_loss: 0.1741 - val_accuracy: 0.9414 - val_auc: 0.8728\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.1419 - accuracy: 0.9463 - auc: 0.9153\n",
      "Epoch 9: val_loss did not improve from 0.16714\n",
      "247/247 [==============================] - 42s 170ms/step - loss: 0.1419 - accuracy: 0.9463 - auc: 0.9153 - val_loss: 0.1832 - val_accuracy: 0.9422 - val_auc: 0.8679\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.1372 - accuracy: 0.9488 - auc: 0.9190\n",
      "Epoch 10: val_loss did not improve from 0.16714\n",
      "247/247 [==============================] - 46s 186ms/step - loss: 0.1372 - accuracy: 0.9488 - auc: 0.9190 - val_loss: 0.1672 - val_accuracy: 0.9434 - val_auc: 0.8799\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.1340 - accuracy: 0.9493 - auc: 0.9223\n",
      "Epoch 11: val_loss did not improve from 0.16714\n",
      "247/247 [==============================] - 32s 130ms/step - loss: 0.1340 - accuracy: 0.9493 - auc: 0.9223 - val_loss: 0.1707 - val_accuracy: 0.9428 - val_auc: 0.8809\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 0.9508 - auc: 0.9299\n",
      "Epoch 12: val_loss did not improve from 0.16714\n",
      "247/247 [==============================] - 29s 116ms/step - loss: 0.1288 - accuracy: 0.9508 - auc: 0.9299 - val_loss: 0.1748 - val_accuracy: 0.9433 - val_auc: 0.8763\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.9510 - auc: 0.9339\n",
      "Epoch 13: val_loss did not improve from 0.16714\n",
      "247/247 [==============================] - 28s 113ms/step - loss: 0.1265 - accuracy: 0.9510 - auc: 0.9339 - val_loss: 0.1851 - val_accuracy: 0.9437 - val_auc: 0.8704\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.9524 - auc: 0.9298\n",
      "Epoch 14: val_loss did not improve from 0.16714\n",
      "247/247 [==============================] - 28s 113ms/step - loss: 0.1294 - accuracy: 0.9524 - auc: 0.9298 - val_loss: 0.2154 - val_accuracy: 0.9450 - val_auc: 0.8541\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.1248 - accuracy: 0.9529 - auc: 0.9342\n",
      "Epoch 15: val_loss did not improve from 0.16714\n",
      "247/247 [==============================] - 28s 115ms/step - loss: 0.1248 - accuracy: 0.9529 - auc: 0.9342 - val_loss: 0.1836 - val_accuracy: 0.9418 - val_auc: 0.8715\n",
      "Epoch 16/20\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.1269 - accuracy: 0.9531 - auc: 0.9324\n",
      "Epoch 16: val_loss did not improve from 0.16714\n",
      "247/247 [==============================] - 29s 117ms/step - loss: 0.1269 - accuracy: 0.9531 - auc: 0.9324 - val_loss: 0.1895 - val_accuracy: 0.9443 - val_auc: 0.8705\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 0.9541 - auc: 0.9397\n",
      "Epoch 17: val_loss did not improve from 0.16714\n",
      "247/247 [==============================] - 29s 116ms/step - loss: 0.1192 - accuracy: 0.9541 - auc: 0.9397 - val_loss: 0.1854 - val_accuracy: 0.9438 - val_auc: 0.8758\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.1186 - accuracy: 0.9543 - auc: 0.9399\n",
      "Epoch 18: val_loss did not improve from 0.16714\n",
      "247/247 [==============================] - 34s 137ms/step - loss: 0.1186 - accuracy: 0.9543 - auc: 0.9399 - val_loss: 0.1853 - val_accuracy: 0.9426 - val_auc: 0.8744\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.9556 - auc: 0.9462\n",
      "Epoch 19: val_loss did not improve from 0.16714\n",
      "247/247 [==============================] - 27s 109ms/step - loss: 0.1137 - accuracy: 0.9556 - auc: 0.9462 - val_loss: 0.1889 - val_accuracy: 0.9445 - val_auc: 0.8670\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.1213 - accuracy: 0.9556 - auc: 0.9371\n",
      "Epoch 20: val_loss did not improve from 0.16714\n",
      "247/247 [==============================] - 27s 108ms/step - loss: 0.1213 - accuracy: 0.9556 - auc: 0.9371 - val_loss: 0.1919 - val_accuracy: 0.9428 - val_auc: 0.8667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8b00a4f70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x_train, results_train], labels_train, epochs=20, batch_size = 128, validation_split=0.2, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " emb_layer (emb_layer)       multiple                  3568      \n",
      "                                                                 \n",
      " emb_layer_1 (emb_layer)     multiple                  1448      \n",
      "                                                                 \n",
      " emb_layer_2 (emb_layer)     multiple                  29600     \n",
      "                                                                 \n",
      " emb_layer_3 (emb_layer)     multiple                  1432      \n",
      "                                                                 \n",
      " emb_layer_4 (emb_layer)     multiple                  1392      \n",
      "                                                                 \n",
      " emb_layer_5 (emb_layer)     multiple                  1376      \n",
      "                                                                 \n",
      " emb_layer_6 (emb_layer)     multiple                  1416      \n",
      "                                                                 \n",
      " emb_layer_7 (emb_layer)     multiple                  1432      \n",
      "                                                                 \n",
      " emb_layer_8 (emb_layer)     multiple                  1416      \n",
      "                                                                 \n",
      " emb_layer_9 (emb_layer)     multiple                  1400      \n",
      "                                                                 \n",
      " emb_layer_10 (emb_layer)    multiple                  1400      \n",
      "                                                                 \n",
      " emb_layer_11 (emb_layer)    multiple                  1552      \n",
      "                                                                 \n",
      " emb_layer_12 (emb_layer)    multiple                  1840      \n",
      "                                                                 \n",
      " emb_layer_13 (emb_layer)    multiple                  1840      \n",
      "                                                                 \n",
      " emb_layer_14 (emb_layer)    multiple                  1376      \n",
      "                                                                 \n",
      " emb_layer_15 (emb_layer)    multiple                  1400      \n",
      "                                                                 \n",
      " emb_layer_16 (emb_layer)    multiple                  1384      \n",
      "                                                                 \n",
      " emb_layer_17 (emb_layer)    multiple                  1400      \n",
      "                                                                 \n",
      " emb_layer_18 (emb_layer)    multiple                  1376      \n",
      "                                                                 \n",
      " emb_layer_19 (emb_layer)    multiple                  1400      \n",
      "                                                                 \n",
      " emb_layer_20 (emb_layer)    multiple                  1400      \n",
      "                                                                 \n",
      " emb_layer_21 (emb_layer)    multiple                  1432      \n",
      "                                                                 \n",
      " emb_layer_22 (emb_layer)    multiple                  1400      \n",
      "                                                                 \n",
      " emb_layer_23 (emb_layer)    multiple                  1392      \n",
      "                                                                 \n",
      " emb_layer_24 (emb_layer)    multiple                  1392      \n",
      "                                                                 \n",
      " emb_layer_25 (emb_layer)    multiple                  1400      \n",
      "                                                                 \n",
      " emb_layer_26 (emb_layer)    multiple                  1400      \n",
      "                                                                 \n",
      " emb_layer_27 (emb_layer)    multiple                  1392      \n",
      "                                                                 \n",
      " concatenate (Concatenate)   multiple                  0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            multiple                  864       \n",
      "                                                                 \n",
      " dense_57 (Dense)            multiple                  2112      \n",
      "                                                                 \n",
      " dense_58 (Dense)            multiple                  922560    \n",
      "                                                                 \n",
      " dense_59 (Dense)            multiple                  61504     \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            multiple                  65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,057,761\n",
      "Trainable params: 1,057,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fb79c6622f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"models/model_checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 17:29:40.829661: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-26 17:29:40.833121: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-26 17:29:40.835950: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-06-26 17:29:41.158570: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-26 17:29:41.164772: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-26 17:29:41.169419: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 22s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.4982749e-03],\n",
       "       [4.1262710e-01],\n",
       "       [4.0728624e-05],\n",
       "       ...,\n",
       "       [2.0841895e-04],\n",
       "       [1.0664350e-01],\n",
       "       [1.1366428e-02]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict([x_test, results_test])\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"solution.txt\", preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
